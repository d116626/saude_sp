{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud import bigquery\n",
    "# from google.cloud import storage\n",
    "\n",
    "\n",
    "def save_in_storage(local_file_name, storage_file_name, local_path_to_file, storage_paht_to_save):\n",
    "    \"\"\"\n",
    "    local_file_name: nome da tabela local\n",
    "    storage_file_name: nome da tabela que sera criada no storage\n",
    "    local_path_to_file: caminho para a pasta local onde se encontra a tabela\n",
    "    storage_paht_to_save: nome da pasta onde os dados serão salvos no storage    \n",
    "    \"\"\"\n",
    "    file_path_csv = \"{}/{}.csv\".format(local_path_to_file,local_file_name)\n",
    "    file_path_parquet = \"{}/{}.parquet\".format(local_path_to_file,local_file_name)\n",
    "    pd.read_csv(file_path_csv).to_parquet(file_path_parquet, index=False)\n",
    "    storage_file_name_parquet = \"{}.parquet\".format(storage_file_name)\n",
    "    \n",
    "    client = storage.Client(project='gabinete-sv')\n",
    "    bucket = client.get_bucket('gabinete-sv')\n",
    "              \n",
    "    blob = bucket.blob('{}/{}'.format(storage_paht_to_save,storage_file_name_parquet))\n",
    "    blob.upload_from_filename(file_path_parquet)\n",
    "    \n",
    "\n",
    "\n",
    "def create_in_bquery(sorage_file_name,bquery_table_name,conjunto_de_dados,sorage_paht_to_file):\n",
    "    \"\"\"\n",
    "    bquery_table_name: nome da tabela que sera criada no bigquery\n",
    "    sorage_file_name: nome da tabela do storage\n",
    "    conjunto de dados: nome do schema onde sera salvo a tabela\n",
    "    sorage_paht_to_file: nome da pasta onde se encontra os dados no storage    \n",
    "    \"\"\"\n",
    "\n",
    "    client = bigquery.Client( project='gabinete-sv')\n",
    "    \n",
    "    dataset_ref = client.dataset(conjunto_de_dados)\n",
    "    \n",
    "    #nome da tabela que será criada no big query\n",
    "    table_name = dataset_ref.table(bquery_table_name)\n",
    "    \n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    #overwite table\n",
    "    job_config.write_disposition = \"WRITE_TRUNCATE\"\n",
    "    #source format\n",
    "    job_config.source_format = bigquery.SourceFormat.PARQUET\n",
    "    \n",
    "    \n",
    "    uri = \"gs://gabinete-sv/{}/{}.parquet\".format(sorage_paht_to_file,sorage_file_name)\n",
    "        \n",
    "    \n",
    "    load_job = client.load_table_from_uri(uri, table_name, job_config=job_config)  # API request\n",
    "    \n",
    "    print(\"Starting job {}\".format(load_job.job_id))\n",
    "\n",
    "    load_job.result()  # Waits for table load to complete.\n",
    "    print(\"Job finished.\")\n",
    "\n",
    "    destination_table = client.get_table(dataset_ref.table(bquery_table_name))\n",
    "    print(\"Loaded {} rows.\".format(destination_table.num_rows))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import xmltodict\n",
    "\n",
    "import untangle\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = 9999\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from gcloud import storage\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot, offline\n",
    "offline.init_notebook_mode(connected=True)\n",
    "import plotly.express as px\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (12, 12)\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# For changes in .py\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "stats = ['skew', 'mad', 'kurt']\n",
    "\n",
    "\n",
    "import qgrid\n",
    "\n",
    "def qg(df):\n",
    "    return(qgrid.show_grid(df,show_toolbar=True, grid_options={'forceFitColumns': False}))\n",
    "\n",
    "import itertools\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.width', -1)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import xmltodict\n",
    "import re\n",
    "import urllib.request as urllib2\n",
    "import io\n",
    "import yaml\n",
    "\n",
    "import math\n",
    "import pysal as ps\n",
    "\n",
    "# from pysal.esda.mapclassify import Quantiles, Equal_Interval, Fisher_Jenks\n",
    "\n",
    "\n",
    "\n",
    "import imageio\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/mnt/AEB0CCA7B0CC777D/jlab/gabinete_sv_credentials.json\"\n",
    "\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "today = str(date.today()).replace('-','_')\n",
    "\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "import wget\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects import pandas2ri\n",
    "utils = rpackages.importr('read.dbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "anos   = ['18','19']\n",
    "months = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "\n",
    "\n",
    "for ano in anos:\n",
    "    for mes in months:\n",
    "        file = 'SPSP{}{}.dbc'.format(ano,mes)\n",
    "        url =     'ftp://ftp.datasus.gov.br/dissemin/publicos/SIHSUS/200801_/Dados/{}'.format(file)\n",
    "        try:\n",
    "            wget.download(url, out='SIHSUS/dbc')\n",
    "            print(file)\n",
    "        except:\n",
    "            print('Error on file: {}'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dbc = 'SIHSUS/dbc'\n",
    "path_parquet = 'SIHSUS/parquet'\n",
    "onlyfiles = [f for f in listdir(path_dbc) if isfile(join(path_dbc, f))]\n",
    "file_dbc = [\"{}/{}\".format(path_dbc,file) for file in onlyfiles]\n",
    "file_parquet = [\"{}/{}\".format(path_parquet,file.replace('.dbc','.parquet')) for file in onlyfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIHSUS/parquet/SPSP1801.parquet\n",
      "SIHSUS/parquet/SPSP1802.parquet\n",
      "SIHSUS/parquet/SPSP1803.parquet\n",
      "SIHSUS/parquet/SPSP1804.parquet\n",
      "SIHSUS/parquet/SPSP1805.parquet\n",
      "SIHSUS/parquet/SPSP1806.parquet\n",
      "SIHSUS/parquet/SPSP1807.parquet\n",
      "SIHSUS/parquet/SPSP1808.parquet\n",
      "SIHSUS/parquet/SPSP1809.parquet\n",
      "SIHSUS/parquet/SPSP1810.parquet\n",
      "SIHSUS/parquet/SPSP1811.parquet\n",
      "SIHSUS/parquet/SPSP1812.parquet\n"
     ]
    }
   ],
   "source": [
    "for dbc_file, parquet_file in zip(file_dbc, file_parquet):\n",
    "    \n",
    "    if path.exists(parquet_file):\n",
    "        print(parquet_file)\n",
    "        pass\n",
    "    else:\n",
    "        r_df = utils.read_dbc(dbc_file)\n",
    "        pd.DataFrame.from_dict({ key : np.asarray(r_df.rx2(key)) for key in r_df.names }).to_parquet(parquet_file, index=False)\n",
    "        del r_df\n",
    "        gc.collect()\n",
    "        print(parquet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
